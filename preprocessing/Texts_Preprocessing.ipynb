{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd9b41e7-a5bf-40e7-b4c5-56ffa647a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa674183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import functions as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9504d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # max num of texts per author\n",
    "\n",
    "texts = mf.read_texts(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "261c3657-5d90-446b-a16f-7041681f91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Evaluate the size of the corpus before preprocessing\n",
    "corpus_size = mf.get_corpus_size(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa3eb3d5-42a9-49b8-b27d-a39c65c96c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Named entity recognition + tokenization\n",
    "\n",
    "texts_ne = mf.get_named_ents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df771600-40f0-4b45-b8bd-c639ad71f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Remove punctuation\n",
    "\n",
    "texts_clean = mf.clean_texts(texts_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b4b2496-4405-4c74-9076-2259780dbee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Lemmatize\n",
    "\n",
    "lemmas = mf.get_lemmas(texts_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997350ce-a391-47d9-aa19-d8600599db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Remove lemmas with length 2 and less\n",
    "\n",
    "lemmas_no_short = [[word for word in text if len(word) > 2] \\\n",
    "                   for text in lemmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6c54630-f54c-4b1f-a33f-bd1f4c1e0fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Remove stopwords\n",
    "\n",
    "lemmas_no_sw = mf.remove_stopwords(lemmas_no_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed90c114-593f-49a2-8b75-350f3dcb0fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 7. Retrieve collocations/n-grams\n",
    "\n",
    "texts_ngrams = mf.get_ngrams(lemmas_no_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c3551fe-699f-481e-9ee4-f4b8a84ae78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Keep nouns only\n",
    "\n",
    "nouns = mf.get_nouns(texts_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2577e4d2-e715-4eb6-8227-a38295a30197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 (alt). Keep nouns and adjectives only\n",
    "\n",
    "nouns_adj = mf.get_nouns_adj(texts_ngrams)\n",
    "\n",
    "# Save\n",
    "with open(f'tokens.json', 'w') as f:\n",
    "    json.dump(nouns_adj, f, indent=4)\n",
    "# Load\n",
    "with open(f'tokens.json', 'r') as f:\n",
    "    nouns_adj = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f19ef6bb-58ca-4ca4-ad91-05320faffab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1260\n",
      "\n",
      "Corpus size\n",
      "\tBefore preprocessing: 1,585,992\n",
      "\tAfter tokenization and NER: 1,952,298\n",
      "\tAfter lemmatization: 1,570,105\n",
      "\tAfter stopwords removal: 987,524\n",
      "\tAfter n-gram extraction: 955,746\n",
      "\tAfter bad POS removal (nouns): 513,409\n",
      "\tAfter bad POS removal (nouns and adj): 690,221\n"
     ]
    }
   ],
   "source": [
    "# Statistics\n",
    "\n",
    "print(f'Number of documents: {len(texts)}')\n",
    "print(f'\\nCorpus size\\n\\tBefore preprocessing: {corpus_size:,}' +\n",
    "      f'\\n\\tAfter tokenization and NER: {sum([len(doc) for doc in texts_ne]):,}' +\n",
    "      f'\\n\\tAfter lemmatization: {sum([len(doc) for doc in lemmas]):,}' +\n",
    "      f'\\n\\tAfter stopwords removal: {sum([len(doc) for doc in lemmas_no_sw]):,}' +\n",
    "      f'\\n\\tAfter n-gram extraction: {sum([len(doc) for doc in texts_ngrams]):,}' +\n",
    "      f'\\n\\tAfter bad POS removal (nouns): {sum([len(doc) for doc in nouns]):,}' +\n",
    "      f'\\n\\tAfter bad POS removal (nouns and adj): {sum([len(doc) for doc in nouns_adj]):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a73db204-d603-4b35-9234-0bed2e789112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Александр Козловский:\n",
      "\tNumber of articles: 43\n",
      "\tTotal number of words: 38259\n",
      "\tAverage number of words in an article: 890\n",
      "\n",
      "Александр Марков:\n",
      "\tNumber of articles: 100\n",
      "\tTotal number of words: 163181\n",
      "\tAverage number of words in an article: 1632\n",
      "\n",
      "Александр Сергеев:\n",
      "\tNumber of articles: 84\n",
      "\tTotal number of words: 47791\n",
      "\tAverage number of words in an article: 569\n",
      "\n",
      "Алексей Гиляров:\n",
      "\tNumber of articles: 100\n",
      "\tTotal number of words: 83601\n",
      "\tAverage number of words in an article: 836\n",
      "\n",
      "Алексей Левин:\n",
      "\tNumber of articles: 85\n",
      "\tTotal number of words: 178758\n",
      "\tAverage number of words in an article: 2103\n",
      "\n",
      "Алексей Опаев:\n",
      "\tNumber of articles: 61\n",
      "\tTotal number of words: 60229\n",
      "\tAverage number of words in an article: 987\n",
      "\n",
      "Аркадий Курамшин:\n",
      "\tNumber of articles: 42\n",
      "\tTotal number of words: 44658\n",
      "\tAverage number of words in an article: 1063\n",
      "\n",
      "Варвара Веденина:\n",
      "\tNumber of articles: 67\n",
      "\tTotal number of words: 64950\n",
      "\tAverage number of words in an article: 969\n",
      "\n",
      "Вера Башмакова:\n",
      "\tNumber of articles: 55\n",
      "\tTotal number of words: 52421\n",
      "\tAverage number of words in an article: 953\n",
      "\n",
      "Владислав Стрекопытов:\n",
      "\tNumber of articles: 98\n",
      "\tTotal number of words: 109166\n",
      "\tAverage number of words in an article: 1114\n",
      "\n",
      "Вячеслав Калинин:\n",
      "\tNumber of articles: 54\n",
      "\tTotal number of words: 56397\n",
      "\tAverage number of words in an article: 1044\n",
      "\n",
      "Елена Наймарк:\n",
      "\tNumber of articles: 100\n",
      "\tTotal number of words: 102996\n",
      "\tAverage number of words in an article: 1030\n",
      "\n",
      "Игорь Иванов:\n",
      "\tNumber of articles: 100\n",
      "\tTotal number of words: 167535\n",
      "\tAverage number of words in an article: 1675\n",
      "\n",
      "Сергей Ястребов:\n",
      "\tNumber of articles: 85\n",
      "\tTotal number of words: 192578\n",
      "\tAverage number of words in an article: 2266\n",
      "\n",
      "Татьяна Романовская:\n",
      "\tNumber of articles: 42\n",
      "\tTotal number of words: 76565\n",
      "\tAverage number of words in an article: 1823\n",
      "\n",
      "Юлия Кондратенко:\n",
      "\tNumber of articles: 56\n",
      "\tTotal number of words: 51499\n",
      "\tAverage number of words in an article: 920\n",
      "\n",
      "Юрий Ерин:\n",
      "\tNumber of articles: 88\n",
      "\tTotal number of words: 95408\n",
      "\tAverage number of words in an article: 1084\n",
      "\n",
      "Total number of authors: 17\n",
      "Total number of articles: 1260\n",
      "Corpus size (before preprocessing): 1,585,992\n"
     ]
    }
   ],
   "source": [
    "# More statistics\n",
    "\n",
    "mf.get_stats('EL', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1570a454-1255-470c-ba99-4ecfbd127dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "a72475a4e957f639a8707c38a651116e9f027e6c6985c08c8cef46a94d0a95f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
